Task 1: Data Exploration insights - Sales effectiveness

Exploratory Data Analysis and insights are given above.

Task 2: ML model to predict the Lead Category (High Potential, Low Potential) After data preprocessing the data was trained and tested by different ML models.

I have used different techniques that are Normal approach then performed Hyperparameter tuning when model was overfitting or underfitting and Boosting.

Logistic Regression did performed moderately on training as well as testing data. so I used bagging to logistic regression after that it performed better but that was not sufficient for us.

Naive Bayes and SVC did not performed well on training as well as testing data.

Decision Tree also performed moderately on both training and testing data. Then I did Hyperparameter tuning for decision tree but then performence of the model incresed by 2%.

Random Forest performed well on both training and testing data but it looks overfitted, to generalize the model I did hyperparameter tuning for random forest but model's performance decreased by 1% but good thing is it is generalized model.

KNN model also a moderate performer.

Bagging for Random Forest and Logistic Regression gives us the same results.

Gradient Boosting performed well on both training and testing data that is 75% testing accuracy and 77% training accuracy

Extreme Gradient Boosting [XGB] Gives us Highest accuracy score for both training data and testing data that is 77% testing accuracy and 88% training accuracy.

XGB model is the generalized and high performed Model among all of them.
